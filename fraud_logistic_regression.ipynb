{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().value_counts()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Time and Amount\n",
    "scaler = StandardScaler()\n",
    "data[['Time', 'Amount']] = scaler.fit_transform(data[['Time', 'Amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and target\n",
    "X = data.drop(columns=['Class'])\n",
    "y = data['Class']\n",
    "\n",
    "# Stratified train-test split to maintain class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    #here we spilted the data into test(20%) and training(80%)\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Display, to ensure that the data was slit correctly\n",
    "X_train.shape, X_test.shape, y_train.value_counts(), y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logistic_model.fit(X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "y_pred_prob = logistic_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using classification report and Precision-Recall AUC\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "pr_auc = auc(recall, precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, label=f\"PR AUC = {pr_auc:.4f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "report, pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Non-Fraud\", \"Fraud\"])\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision = 90/(90 + 1458) = 0.058\n",
    "Only about 5.8% of the transactions flagged as fraud were actually fraud.\n",
    "\n",
    "Recall = 90/(90 + 8) = 0.918\n",
    "The model detected about 91.8% of the actual fraud cases.\n",
    "\n",
    "Accuracy = (90 + 55406)/(55406 + 1458 + 90 + 8) = 0.974\n",
    "About 97.4% of all transactions were classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision and recall for different thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Find thresholds and metrics\n",
    "threshold_metrics = pd.DataFrame({\n",
    "    'Threshold': thresholds,\n",
    "    'Precision': precision[:-1],  # Exclude the last element (thresholds and precision lengths differ)\n",
    "    'Recall': recall[:-1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, precision[:-1], label=\"Precision\")\n",
    "plt.plot(thresholds, recall[:-1], label=\"Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision and Recall vs. Threshold\")B\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold = 0.99\n",
    "y_pred_new = (y_pred_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "# Generate the confusion matrix with the new threshold\n",
    "cm_new = confusion_matrix(y_test, y_pred_new)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_new, display_labels=[\"Non-Fraud\", \"Fraud\"])\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(f\"Confusion Matrix (Threshold = {optimal_threshold})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision = 86/(86 + 69) = 0.555\n",
    "Precision is about 55.5%.\n",
    "\n",
    "Recall = 86/(86 + 12) = 0.878\n",
    "Recall is about 87.8%.\n",
    "\n",
    "Accuracy = (86 + 56795)/(56795 + 69 + 12 + 86) = 0.998\n",
    "Accuracy is 99.8%, but this can be misleading in imbalanced datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
